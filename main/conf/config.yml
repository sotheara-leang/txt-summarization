emb-size: 50 # 100 - Glove
hidden-size: 50 # 200

max-enc-steps: 100
max-dec-steps: 100

vocab-size: 50000
vocab-file: data/extract/giga-vocab.txt

model-file: data/extract/giga-model.ckpt

sharing-decoder-weight: true

train:
  epoch: 5
  batch-size: 50
  log-batch: true
  log-batch-interval: 1
  clip-gradient-max-norm: 1

  lr: 0.001
  lr-decay: 1
  lr-decay-epoch: 50

  ml:
    enable: true
    forcing-ratio: 1
    forcing-decay: 0
  rl:
    enable: false
    transit-epoch: -1
    transit-decay: 0
    weight: 0.9984

  eval: true

  dir: data/extract
  output-dir: data/result
  tb-log-dir: logs/giga-5k/

  article-file: giga-article.txt
  summary-file: giga-summary.txt
  vocab-file: giga-vocab.txt
  emb-file: embedding
  model-file:
  save-model-file: giga-model.ckpt